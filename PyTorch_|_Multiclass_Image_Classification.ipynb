{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "PyTorch | Multiclass Image Classification",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrSaggio/NEIRO/blob/main/PyTorch_%7C_Multiclass_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For neural network model summary, similar to Keras\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-03-04T20:45:25.225847Z",
          "iopub.execute_input": "2022-03-04T20:45:25.2262Z",
          "iopub.status.idle": "2022-03-04T20:45:34.722513Z",
          "shell.execute_reply.started": "2022-03-04T20:45:25.226172Z",
          "shell.execute_reply": "2022-03-04T20:45:34.721445Z"
        },
        "trusted": true,
        "id": "jmPJnk96nhLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "CEUx0J4bnmYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML, Javascript\n",
        "\n",
        "color_map = ['#FFFFFF','#FF5733']\n",
        "\n",
        "prompt = color_map[-1]\n",
        "main_color = color_map[0]\n",
        "strong_main_color = color_map[1]\n",
        "custom_colors = [strong_main_color, main_color]\n",
        "\n",
        "css_file = '''\n",
        "div #notebook {\n",
        "background-color: white;\n",
        "line-height: 20px;\n",
        "}\n",
        "\n",
        "#notebook-container {\n",
        "%s\n",
        "margin-top: 2em;\n",
        "padding-top: 2em;\n",
        "border-top: 4px solid %s;\n",
        "-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n",
        "    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n",
        "}\n",
        "\n",
        "div .input {\n",
        "margin-bottom: 1em;\n",
        "}\n",
        "\n",
        ".rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\n",
        "color: %s;\n",
        "font-weight: 600;\n",
        "}\n",
        "\n",
        "div.input_area {\n",
        "border: none;\n",
        "    background-color: %s;\n",
        "    border-top: 2px solid %s;\n",
        "}\n",
        "\n",
        "div.input_prompt {\n",
        "color: %s;\n",
        "}\n",
        "\n",
        "div.output_prompt {\n",
        "color: %s;\n",
        "}\n",
        "\n",
        "div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\n",
        "background: %s;\n",
        "}\n",
        "\n",
        "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
        "    border-color: %s;\n",
        "}\n",
        "\n",
        ".edit_mode div.cell.selected:before {\n",
        "background: %s;\n",
        "}\n",
        "\n",
        ".edit_mode div.cell.selected {\n",
        "border-color: %s;\n",
        "\n",
        "}\n",
        "'''\n",
        "\n",
        "def to_rgb(h):\n",
        "    return tuple(int(h[i:i+2], 16) for i in [0, 2, 4])\n",
        "\n",
        "main_color_rgba = 'rgba(%s, %s, %s, 0.1)' % (to_rgb(main_color[1:]))\n",
        "open('notebook.css', 'w').write(css_file % ('width: 95%;', main_color, main_color, main_color_rgba,\n",
        "                                            main_color,  main_color, prompt, main_color, main_color,\n",
        "                                            main_color, main_color))\n",
        "\n",
        "def nb():\n",
        "    return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\n",
        "nb()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "jupyter": {
          "source_hidden": true
        },
        "id": "OkPNWVffnhLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import collections\n",
        "import torchsummary\n",
        "from torchvision import utils\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch\n",
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "path = '/kaggle/working/data'\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-04T20:45:34.724695Z",
          "iopub.execute_input": "2022-03-04T20:45:34.725133Z",
          "iopub.status.idle": "2022-03-04T20:45:34.746341Z",
          "shell.execute_reply.started": "2022-03-04T20:45:34.725081Z",
          "shell.execute_reply": "2022-03-04T20:45:34.745409Z"
        },
        "trusted": true,
        "id": "5m796CGPnhLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>1 |</span> INTRODUCTION</b>\n",
        "\n",
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>1.1 | STL-10 DATASET</b></p>\n",
        "</div>\n",
        "\n",
        "In the current problem, a datset consisting of 10 classes (__STL-10__) is used as a basis for a **<span style='color:#F1C40F'>multiclass image classification problem</span>**\n",
        "\n",
        "> - The STL-10 dataset is an image recognition dataset for developing unsupervised feature learning, deep learning, self-taught learning algorithms\n",
        "> - It is inspired by the CIFAR-10 dataset but with some modifications. In particular, each class has fewer labeled training examples than in CIFAR-10, but a very large set of unlabeled examples is provided to learn image models prior to supervised training\n",
        "> - The primary challenge is to make use of the unlabeled data (which comes from a similar but different distribution from the labeled data) to build a useful prior\n",
        "> - We also expect that the higher resolution of this dataset (96x96) will make it a challenging benchmark for developing more scalable unsupervised learning methods\n",
        "\n",
        "\n",
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>1.2 | INITIALISATION OF CNN NETWORK</b></p>\n",
        "</div>\n",
        "\n",
        "\n",
        "The aim is to train a __CNN__ model using two approaches:\n",
        "- (I) randomised weight initialisation\n",
        "- (II) transfer learning weight initialisation\n",
        "\n",
        "and compare the difference between the two.\n",
        "\n",
        "- __Randomised Initialisation__ is a prerequisite of neural networks to start learning and updating subsequent weights in an interative manner, the downside is that __it can take a while for a network to learn something about the dataset__, this is a very typical issue encountered in the solution of Partial Differential Equations (PDE), initial conditions can affect the solution\n",
        "- Likewise, we can set an assumption: we can __potentially benefit from previous model weights__, in order to obtain an accurate model much quicker, provided these model weights actually are useful for a particular problem, this process is often called **<span style='color:#F1C40F'>Transfer Learning</span>**, simply implying neural network coefficient initialisation is prestructured\n",
        "\n",
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>1.3 | PRETRAINED MODELS</b></p>\n",
        "</div>\n",
        "\n",
        "- For our model, a prexisting model will be used; **[resnet18](https://pytorch.org/vision/0.8/models.html)** is one of the available preset models, having already been pretrained on a much larger dataset, thus we can potentially benefit from these coefficients for our classification problem using the **<span style='color:#F1C40F'>STL-10</span>** dataset\n",
        "- We will try both of the weight initialisations stated above and compare the results using the **<span style='color:#F1C40F'>resnet18</span>** CNN model\n",
        "\n"
      ],
      "metadata": {
        "id": "zWYB90zRnhLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>2 |</span> GET THE TRAINING DATA</b>\n",
        "\n",
        "- We will be using the **<span style='color:#F1C40F'>STL-10</span>** for this problem, available from the\n",
        "<code>torchvision.datasets</code> module.\n",
        "\n",
        "__Our Dataset Division__\n",
        "- **<span style='color:#F1C40F'>STL-10</span>** contains 10 unique classes, <code>collections.Counter()</code> can be used to count all the unique images for each class.\n",
        "- Training Dataset: 5000 images (3 channels 96x96 px)\n",
        "- Evaluation & Test Set: 8000: (3 channels 96x96 px)"
      ],
      "metadata": {
        "id": "ZNVJIUTunhLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 1. Training STL-10 Dataset '''\n",
        "# Fetch the data & convert numpy to pytorch tensor format\n",
        "\n",
        "transf = transforms.Compose([transforms.ToTensor()])\n",
        "train_ds = datasets.STL10(path,download=True,\n",
        "                          split='train',\n",
        "                          transform=transf)\n",
        "\n",
        "''' 2. Test / Evaluation STL-10 Dataset '''\n",
        "\n",
        "test_all = datasets.STL10(path,\n",
        "                          download=True,\n",
        "                          split='test',\n",
        "                          transform=transf)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:03:10.560484Z",
          "iopub.execute_input": "2022-02-23T09:03:10.560845Z",
          "iopub.status.idle": "2022-02-23T09:06:22.605713Z",
          "shell.execute_reply.started": "2022-02-23T09:03:10.56081Z",
          "shell.execute_reply": "2022-02-23T09:06:22.604688Z"
        },
        "trusted": true,
        "id": "cibivs5rnhLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data stored in torchvision.datasets format\n",
        "print(type(train_ds))\n",
        "print(type(train_ds.data))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:06:22.607189Z",
          "iopub.execute_input": "2022-02-23T09:06:22.607599Z",
          "iopub.status.idle": "2022-02-23T09:06:22.612491Z",
          "shell.execute_reply.started": "2022-02-23T09:06:22.607563Z",
          "shell.execute_reply": "2022-02-23T09:06:22.611623Z"
        },
        "trusted": true,
        "id": "cVqx_NA-nhLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the numpy array data\n",
        "print(f'Shape of training set: {train_ds.data.shape}')\n",
        "print(f'Shape of test set: {test_all.data.shape}')  # both evaluation & test sets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:06:22.615221Z",
          "iopub.execute_input": "2022-02-23T09:06:22.615667Z",
          "iopub.status.idle": "2022-02-23T09:06:22.634244Z",
          "shell.execute_reply.started": "2022-02-23T09:06:22.615626Z",
          "shell.execute_reply": "2022-02-23T09:06:22.632776Z"
        },
        "trusted": true,
        "id": "V6WFs1vdnhLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Images have three channels & have a dimension of 96 x 96 px\n",
        "-  <code>collections.Counter()</code> can be used to count all the unique images for each class"
      ],
      "metadata": {
        "id": "hxRh8ctJnhLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of images per category\n",
        "y_train = [y for _,y in train_ds]\n",
        "counter_train = collections.Counter(y_train)\n",
        "print('Class Image Counter for Training Data')\n",
        "print(counter_train,'\\n')\n",
        "\n",
        "# Count the number of images per category\n",
        "y_testall = [y for _,y in test_all]\n",
        "counter_testall = collections.Counter(y_testall)\n",
        "print('Class Image Counter for Test Data')\n",
        "print(counter_testall)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:06:22.637313Z",
          "iopub.execute_input": "2022-02-23T09:06:22.637641Z",
          "iopub.status.idle": "2022-02-23T09:06:26.274713Z",
          "shell.execute_reply.started": "2022-02-23T09:06:22.637615Z",
          "shell.execute_reply": "2022-02-23T09:06:26.273758Z"
        },
        "trusted": true,
        "id": "aKBMqxm8nhLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>3 |</span> SPLITTING TEST DATA</b>\n",
        "\n",
        "- Having downloaded the dataset __test_all__, which will be used for evaluation & test evaluation, we need to split them, we will use **<span style='color:#F1C40F'>StratifiedShuffleSplit</span>**\n",
        "- A **<span style='color:#F1C40F'>80/20</span>** division is used for the evaluation/test datasets"
      ],
      "metadata": {
        "id": "dyMxbmSdnhLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "''' Stratified Shuffle Splitting '''\n",
        "# using stratified splitting of classes\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1,\n",
        "                               test_size=0.2,\n",
        "                               random_state=0)\n",
        "\n",
        "indices = list(range(len(test_all))) # make index list for upto max value\n",
        "y_test0 = [y for _,y in test_all]    # extract list of all class ids\n",
        "\n",
        "''' Validation / Test Split Index '''\n",
        "\n",
        "print('Validation / Test Split Index:')\n",
        "for idx_test,idx_val in split.split(indices,y_test0):\n",
        "    print(\"Test Indicies:\", idx_test)\n",
        "    print(\"Validation Indicies:\", idx_val)\n",
        "    print(len(idx_val),len(idx_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:06:26.27599Z",
          "iopub.execute_input": "2022-02-23T09:06:26.276508Z",
          "iopub.status.idle": "2022-02-23T09:06:29.052361Z",
          "shell.execute_reply.started": "2022-02-23T09:06:26.276469Z",
          "shell.execute_reply": "2022-02-23T09:06:29.05125Z"
        },
        "trusted": true,
        "id": "FqiV3NBbnhLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using **<span style='color:#F1C40F'>Subset</span>**, we can generate torch datasets"
      ],
      "metadata": {
        "id": "NlGa_wEPnhLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Create two datasets from test_all '''\n",
        "# use torch utility to make subsets for test_all\n",
        "\n",
        "val_ds = Subset(test_all,\n",
        "                idx_val)  # list of indicies for valid split\n",
        "test_ds = Subset(test_all,\n",
        "                 idx_test) # list of indicies for test split\n",
        "\n",
        "''' Recount the number of images per class (similar to training data)'''\n",
        "\n",
        "y_test = [y for _,y in test_ds]\n",
        "y_val = [y for _,y in val_ds]\n",
        "\n",
        "counter_test = collections.Counter(y_test)\n",
        "counter_val = collections.Counter(y_val)\n",
        "print(counter_test)\n",
        "print(counter_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:06:37.818372Z",
          "iopub.execute_input": "2022-02-23T09:06:37.818892Z",
          "iopub.status.idle": "2022-02-23T09:06:40.361245Z",
          "shell.execute_reply.started": "2022-02-23T09:06:37.818855Z",
          "shell.execute_reply": "2022-02-23T09:06:40.360503Z"
        },
        "trusted": true,
        "id": "FljxBCJ6nhLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>4 |</span> PLOTTING TENSOR DATA</b>\n",
        "\n",
        "- Let's plot our dataset, so we know what exactly our classes represent. Examples are taken from the validation dataset; <code>val_ds</code>\n",
        "- Looks like our classes represent in order:\n",
        "> Aircraft (0), Birds (1), Automobiles (2), Cats (3), Deers (4), Dogs (5), Horses (6), Monkeys (7), Ships (8), Trucks (9); a total of 10 classes."
      ],
      "metadata": {
        "id": "z1ZxmKxonhLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_img(img,y=None,color=True):\n",
        "    npimg = img.numpy()\n",
        "    npimg_T = np.transpose(npimg,(1,2,0))\n",
        "    plt.imshow(npimg_T)\n",
        "    plt.title('Image samples from each of the 10 classes')\n",
        "    plt.axis('on')\n",
        "\n",
        "# Plot PyTorch Tensor Samples\n",
        "def plot_tensor(tensor,random_id=False,class_id=None):\n",
        "\n",
        "    if(random_id is True):\n",
        "        rnd_inds = np.random.randint(0,len(tensor),100)\n",
        "        X_show = [tensor[i][0] for i in rnd_inds]\n",
        "        target = [tensor[i][1] for i in rnd_inds]\n",
        "    else:\n",
        "\n",
        "        if(class_id is None):\n",
        "            X_show = []\n",
        "            # cycle through all classes\n",
        "            for j in range(0,10):\n",
        "                ii=-1\n",
        "                for i in range(0,1000):\n",
        "                    if(tensor[i][1] is j):\n",
        "                        ii+=1\n",
        "                        if(ii>19):\n",
        "                            break\n",
        "                        else:\n",
        "                            X_show.append(tensor[i][0])\n",
        "\n",
        "        if(class_id is not None):\n",
        "\n",
        "            print(f'Showing samples from {len(tensor)} tensors:')\n",
        "\n",
        "            X_show = []\n",
        "            ii=-1\n",
        "            for i in range(0,1000):\n",
        "                if(tensor[i][1] is class_id):\n",
        "                    ii+=1\n",
        "                    if(ii>19):\n",
        "                        break\n",
        "                    else:\n",
        "                        X_show.append(tensor[i][0])\n",
        "\n",
        "\n",
        "    X_grid = utils.make_grid(X_show,nrow=20,padding=1)\n",
        "    plt.figure(figsize=(30,10))\n",
        "    plot_img(X_grid,y=None,color=True)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-02-23T09:20:02.043233Z",
          "iopub.execute_input": "2022-02-23T09:20:02.043576Z",
          "iopub.status.idle": "2022-02-23T09:20:02.054941Z",
          "shell.execute_reply.started": "2022-02-23T09:20:02.043544Z",
          "shell.execute_reply": "2022-02-23T09:20:02.054049Z"
        },
        "trusted": true,
        "id": "PNRwUiUinhLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data from all classes\n",
        "plot_tensor(val_ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:20:06.165903Z",
          "iopub.execute_input": "2022-02-23T09:20:06.166225Z",
          "iopub.status.idle": "2022-02-23T09:20:07.80393Z",
          "shell.execute_reply.started": "2022-02-23T09:20:06.166196Z",
          "shell.execute_reply": "2022-02-23T09:20:07.803051Z"
        },
        "trusted": true,
        "id": "hVsakIbHnhLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data from one class\n",
        "plot_tensor(val_ds,class_id=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:20:08.126132Z",
          "iopub.execute_input": "2022-02-23T09:20:08.126499Z",
          "iopub.status.idle": "2022-02-23T09:20:08.460254Z",
          "shell.execute_reply.started": "2022-02-23T09:20:08.126463Z",
          "shell.execute_reply": "2022-02-23T09:20:08.459258Z"
        },
        "trusted": true,
        "id": "tWMUWWb8nhLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>5 |</span> TRAINING DATASET TRANSFORMATIONS</b>\n",
        "\n",
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>5.1 | TRANSFORMATION LIST</b></p>\n",
        "</div>\n",
        "\n",
        "We'll apply some transformations that will change the image data every epoch, we can visualise the first samples as well\n",
        "> - RandomHorizontalFlip\n",
        "> - RandomVerticalFlip\n",
        "> - ToTensor\n",
        "> - Normalize (custom normaliser)\n",
        "\n",
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>5.2 | CALCULATE THE MEAN & STD OF TRAIN_DS</b></p>\n",
        "</div>\n",
        "\n",
        "For normalisation (Normalize), we need to specify the **mean** & **standard deviation** values we want to use, as part of the trasformation function"
      ],
      "metadata": {
        "id": "QeFt3fUpnhLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_meanstd(data):\n",
        "\n",
        "    # list of lists of mean values for each image\n",
        "    meanRGB = [np.mean(x.numpy(),axis=(1,2)) for x,_ in data]\n",
        "    stdRGB = [np.std(x.numpy(),axis=(1,2)) for x,_ in data]\n",
        "    print('Mean & std values for sample:')\n",
        "    print(meanRGB[0]); print(stdRGB[0])\n",
        "\n",
        "    # global dataset mean of those means\n",
        "    meanR = np.mean([m[0] for m in meanRGB])\n",
        "    meanG = np.mean([m[1] for m in meanRGB])\n",
        "    meanB = np.mean([m[2] for m in meanRGB])\n",
        "\n",
        "    # global dataset standard deviation mean\n",
        "    stdR = np.mean([s[0] for s in stdRGB])\n",
        "    stdG = np.mean([s[1] for s in stdRGB])\n",
        "    stdB = np.mean([s[2] for s in stdRGB])\n",
        "\n",
        "    print('\\nMean value for dataset:')\n",
        "    print(f'Mean Values: {meanR} {meanG} {meanB}')\n",
        "    print(f'STD Values: {stdR} {stdG} {stdB}')\n",
        "\n",
        "    return [meanR,meanG,meanB],[stdR,stdG,stdB]\n",
        "\n",
        "means,stds = get_meanstd(train_ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:08:02.417432Z",
          "iopub.execute_input": "2022-02-23T09:08:02.417783Z",
          "iopub.status.idle": "2022-02-23T09:08:05.995068Z",
          "shell.execute_reply.started": "2022-02-23T09:08:02.417753Z",
          "shell.execute_reply": "2022-02-23T09:08:05.994142Z"
        },
        "trusted": true,
        "id": "jLesE7qvnhLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>5.3 | SET TRANSFORMATIONS</b></p>\n",
        "</div>\n",
        "\n",
        "- Both training & test contain transformers <code>.ToTensor()</code>\n",
        "- We can visually confirm that the transforms **<span style='color:#F1C40F'>RandomHorizontalFlip</span>**, **<span style='color:#F1C40F'>RandomVerticalFlip</span>** have been applied in the dataset\n",
        "- As well as the normalisation, which has changed the colours"
      ],
      "metadata": {
        "id": "KLYUGsHnnhLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Define the image transformations ( for train_ds & test_all) '''\n",
        "\n",
        "# Transformations for training set\n",
        "train_transformer = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                        transforms.RandomVerticalFlip(p=0.5),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([means[0],means[1],means[2]],\n",
        "                                                             [stds[0],stds[1],stds[2]])])\n",
        "\n",
        "# Standard transformations for test set\n",
        "test0_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                        transforms.Normalize([means[0],means[1],means[2]],\n",
        "                                                             [stds[0],stds[1],stds[2]])])\n",
        "\n",
        "''' Update the transform functions for train_ds & test_all '''\n",
        "train_ds.transform = train_transformer\n",
        "test_all.transform = test0_transformer\n",
        "\n",
        "plot_tensor(train_ds,class_id=1) # Can plot the converted data after transformation"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:09:57.014257Z",
          "iopub.execute_input": "2022-02-23T09:09:57.014668Z",
          "iopub.status.idle": "2022-02-23T09:09:57.348453Z",
          "shell.execute_reply.started": "2022-02-23T09:09:57.014626Z",
          "shell.execute_reply": "2022-02-23T09:09:57.347521Z"
        },
        "trusted": true,
        "id": "RVZRVO54nhLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>6 |</span> CREATE DATALOADERS</b>\n",
        "\n",
        "- Next we'll need to create the **<span style='color:#F1C40F'>data loaders</span>**, which will used to access the dataset during training\n",
        "- We need to define a **<span style='color:#F1C40F'>batch_size</span>**:\n",
        "> The number of **<span style='color:#F1C40F'>images extracted from the dataset each iteration</span>**, a batch size of 32 is chosen for the training data & 64 for the evaluation dataset."
      ],
      "metadata": {
        "id": "TnCgAgG3nhLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Create dataloaders from train_ds & val_ds '''\n",
        "\n",
        "# Create Data Loaders (training)\n",
        "train_dl = DataLoader(train_ds,\n",
        "                      batch_size=32,\n",
        "                      shuffle=True)\n",
        "\n",
        "# Create Data Loader (validation)\n",
        "val_dl = DataLoader(val_ds,\n",
        "                    batch_size=64,\n",
        "                    shuffle=False)\n",
        "\n",
        "# And get a batch of data from train_dl\n",
        "for x,y in train_dl:\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break\n",
        "\n",
        "# Extract a batch of data from val_dl\n",
        "for x,y in val_dl:\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:32:15.572783Z",
          "iopub.execute_input": "2022-02-23T09:32:15.573142Z",
          "iopub.status.idle": "2022-02-23T09:32:15.638322Z",
          "shell.execute_reply.started": "2022-02-23T09:32:15.573111Z",
          "shell.execute_reply": "2022-02-23T09:32:15.637458Z"
        },
        "trusted": true,
        "id": "GEdLqg-MnhLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>7 |</span> BUILDING A MODEL</b>\n",
        "\n",
        "- We will be preloading an existing model from the <code>torchvision.models</code> library; **<span style='color:#F1C40F'>resnet18</span>**\n",
        "- The default resnet18 model **<span style='color:#F1C40F'>fc layer</span>** uses 1000 classes:\n",
        "> - (fc): Linear(in_features=512, out_features=1000, bias=True\n",
        "\n",
        "\n",
        "- We'll be changing it to 10 classes resetnet18</code>, so we will need to **<span style='color:#F1C40F'>adjust the final layer (fc)</span>** to match out 10 classes\n",
        "- We will be looking into two cases; a resenet18 model:\n",
        "> - w/ __non pretrained__ coefficients (initialised weights)\n",
        "> - one with __pretrained__ coefficients (via transfer learning)\n"
      ],
      "metadata": {
        "id": "ic-Tq7dVnhLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Non Pretrained Model Variant '''\n",
        "model_resnet18 = models.resnet18(pretrained=False)\n",
        "num_ftrs = model_resnet18.fc.in_features\n",
        "model_resnet18.fc = nn.Linear(num_ftrs,10)\n",
        "\n",
        "# device = torch.device(\"cuda:0\")\n",
        "# model_resnet18.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:41:46.225321Z",
          "iopub.execute_input": "2022-02-23T09:41:46.225695Z",
          "iopub.status.idle": "2022-02-23T09:41:46.417723Z",
          "shell.execute_reply.started": "2022-02-23T09:41:46.225664Z",
          "shell.execute_reply": "2022-02-23T09:41:46.416781Z"
        },
        "trusted": true,
        "id": "1lbb-xWrnhLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Pretrained Model Variant '''\n",
        "pre_resnet18 = models.resnet18(pretrained=True)\n",
        "num_ftrs = pre_resnet18.fc.in_features\n",
        "pre_resnet18.fc = nn.Linear(num_ftrs,10)\n",
        "\n",
        "# device = torch.device(\"cuda:0\")\n",
        "# pre_resnet18.to(device)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-02-23T09:42:57.241153Z",
          "iopub.execute_input": "2022-02-23T09:42:57.241494Z",
          "iopub.status.idle": "2022-02-23T09:42:57.520905Z",
          "shell.execute_reply.started": "2022-02-23T09:42:57.241461Z",
          "shell.execute_reply": "2022-02-23T09:42:57.520092Z"
        },
        "trusted": true,
        "id": "5ZvXSV0fnhLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>8 |</span> DEFINING A LOSS FUNCTION & OPTIMISER</b>\n",
        "\n",
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>8.1 | LOSS FUNCTION</b></p>\n",
        "</div>\n",
        "\n",
        "- The load of defining a loss function is to optimise the model towards a predefined metric\n",
        "- The standard metric used for classification is **<span style='color:#F1C40F'>cross-entropy loss (logloss)</span>**\n",
        "- In the definition of loss function, we need to consider the number of model outputs & the activation functions\n",
        "- For multiclass classification the number of outputs of a model is set to the number of classes, output activation function determines the loss function.\n",
        "\n",
        "__Some Options__\n",
        "\n",
        "- The resnet18 has linear outputs, with **<span style='color:#F1C40F'>no activation function</span>**, so let's choose:\n",
        "> **<span style='color:#F1C40F'>nn.CrossEntropyLoss</span>** - which combines **<span style='color:#F1C40F'>nn.LogSoftmax()</span>** & **<span style='color:#F1C40F'>nn.NLLLoss()</span>** in one class\n",
        "- If output activation uses **<span style='color:#F1C40F'>log_softmax</span>**, we can use **<span style='color:#F1C40F'>nn.NLLLoss</span>**"
      ],
      "metadata": {
        "id": "vW1V2UxMnhLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Defining a Loss Function '''\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:47:58.42916Z",
          "iopub.execute_input": "2022-02-23T09:47:58.429509Z",
          "iopub.status.idle": "2022-02-23T09:47:58.433783Z",
          "shell.execute_reply.started": "2022-02-23T09:47:58.429477Z",
          "shell.execute_reply": "2022-02-23T09:47:58.432853Z"
        },
        "trusted": true,
        "id": "v7vx3HQCnhLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:white;\"><b>8.2 | DEFINING AN OPTIMISER</b></p>\n",
        "</div>\n",
        "\n",
        "- An optimiser will hold the current state & will update the model parameters based on the computed gradients\n",
        "- The **<span style='color:#F1C40F'>choice of an optimiser</span>** in a problem can be **<span style='color:#F1C40F'>considered as a hyperparameter</span>** & an investigation into which one works best is often prefered\n",
        "- PyTorch's **<span style='color:#F1C40F'>torch.optim</span>** also includes other useful tools like a **<span style='color:#F1C40F'>learning scheduler</span>**:\n",
        "> which is useful to adjust the __learning rate__ on the fly automatically during training, in an attempt to improve the model performance\n",
        "\n",
        "\n",
        "- For __classification tasks__, **<span style='color:#F1C40F'>Stochastic Gradient Descent (SGD)</span>** & **<span style='color:#F1C40F'>Adam</span>** Optimisers are very common\n",
        "- __Adam__ Optimiser outperforms SGD when it comes to speed and accuracy more often than not, so let's choose it for this problem"
      ],
      "metadata": {
        "id": "UIuDZbhJnhLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the current learning rate helper function\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T09:57:12.487065Z",
          "iopub.execute_input": "2022-02-23T09:57:12.487463Z",
          "iopub.status.idle": "2022-02-23T09:57:12.49214Z",
          "shell.execute_reply.started": "2022-02-23T09:57:12.487399Z",
          "shell.execute_reply": "2022-02-23T09:57:12.491249Z"
        },
        "trusted": true,
        "id": "r6hPq_8_nhLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Define an optimiser '''\n",
        "optimiser= optim.Adam(model_resnet18.parameters(),\n",
        "                 lr=1e-4)\n",
        "\n",
        "current_lr = get_lr(optimiser)\n",
        "print(f'current lr = {current_lr}')\n",
        "\n",
        "''' Define learning rate scheduler '''\n",
        "lr_scheduler = CosineAnnealingLR(optimiser,\n",
        "                                 T_max=2,\n",
        "                                 eta_min=1e-5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T10:03:23.051583Z",
          "iopub.execute_input": "2022-02-23T10:03:23.052047Z",
          "iopub.status.idle": "2022-02-23T10:03:23.05907Z",
          "shell.execute_reply.started": "2022-02-23T10:03:23.05201Z",
          "shell.execute_reply": "2022-02-23T10:03:23.057903Z"
        },
        "trusted": true,
        "id": "lhob2SBSnhLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_out(loss_hist,metric_hist,epochs=None):\n",
        "\n",
        "    # Train-Validation Progress\n",
        "    fig = make_subplots(rows=1, cols=2,subplot_titles=['lost_hist','metric_hist'])\n",
        "\n",
        "    # Plot Model Learning Rate\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=loss_hist[\"train\"],\n",
        "                             name='loss_hist[\"train\"]',\n",
        "                             line=dict(color=\"#0000ff\")),row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=loss_hist[\"val\"],\n",
        "                             name='loss_hist[\"val\"]'),row=1, col=1)\n",
        "\n",
        "    # Plot Metric\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=metric_hist[\"train\"],\n",
        "                             name='metric_hist[\"train\"]'),row=1, col=2)\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=metric_hist[\"val\"],\n",
        "                             name='metric_hist[\"val\"]'),row=1, col=2)\n",
        "\n",
        "    fig.update_layout(template='plotly_white')\n",
        "    fig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0},height=300)\n",
        "    fig.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-02-23T10:17:26.400568Z",
          "iopub.execute_input": "2022-02-23T10:17:26.400916Z",
          "iopub.status.idle": "2022-02-23T10:17:26.410565Z",
          "shell.execute_reply.started": "2022-02-23T10:17:26.400886Z",
          "shell.execute_reply": "2022-02-23T10:17:26.409541Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "G9dzdjNHnhLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><span style='color:#F1C40F'>9 |</span> MODEL EVALUATION</b>\n",
        "\n",
        "Neural networks need weights initiaisation in either case, we will try two approaches:\n",
        "\n",
        "- __Random weight initialisation__ (standard) approach\n",
        "- __Transfer Learning__ (preloaded model weights) approach"
      ],
      "metadata": {
        "id": "1gSkdzKtnhLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "''' Training and Tranfer Learning '''\n",
        "\n",
        "''' Helper function to count the number of correct predictions '''\n",
        "def metrics_batch(output, target):\n",
        "    # get output class\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "    # compare output class with target class\n",
        "    corrects=pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "''' Helper function to compute the loss value per batch of data '''\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "\n",
        "    # get loss\n",
        "    loss = loss_func(output, target)\n",
        "\n",
        "    # get performance metric\n",
        "    metric_b = metrics_batch(output,target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss.item(), metric_b\n",
        "\n",
        "# define computation hardware approach (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Compute the Loss Value & Performance Metric\n",
        "\n",
        "def loss_epoch(model,loss_func,dataset_dl,check_id=False,opt=None):\n",
        "\n",
        "    # initialising variables\n",
        "    running_loss=0.0\n",
        "    running_metric=0.0\n",
        "    len_data=len(dataset_dl.dataset)\n",
        "\n",
        "    # internal loop\n",
        "    for xb, yb in dataset_dl:\n",
        "\n",
        "        xb=xb.to(device) # move X of batch to device\n",
        "        yb=yb.to(device) # move y of batch to device\n",
        "\n",
        "        output=model(xb) # get model output\n",
        "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n",
        "        running_loss+=loss_b # update running loss\n",
        "\n",
        "        if(metric_b is not None):\n",
        "            running_metric+=metric_b # update running metric\n",
        "        if(check_id):\n",
        "            break # stop if only checking\n",
        "\n",
        "    loss=running_loss/float(len_data) # average loss value\n",
        "    metric=running_metric/float(len_data) # average metric value\n",
        "\n",
        "    return loss, metric"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-02-23T10:17:27.592409Z",
          "iopub.execute_input": "2022-02-23T10:17:27.592757Z",
          "iopub.status.idle": "2022-02-23T10:17:27.602956Z",
          "shell.execute_reply.started": "2022-02-23T10:17:27.592727Z",
          "shell.execute_reply": "2022-02-23T10:17:27.602004Z"
        },
        "trusted": true,
        "id": "b6raqyWOnhLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' TRAINING FUNCTION '''\n",
        "# model - input model\n",
        "# parameters - input parameter dictionary\n",
        "\n",
        "def train_val(model, params, verbose = False):\n",
        "\n",
        "    # extract model parameters\n",
        "    epochs=params[\"epochs\"]\n",
        "    loss_func=params[\"loss_func\"]\n",
        "    opt=params[\"optimiser\"]\n",
        "    train_dl=params[\"train_dl\"]\n",
        "    val_dl=params[\"val_dl\"]\n",
        "    check_id=params[\"check_id\"]\n",
        "    lr_scheduler=params[\"lr_scheduler\"]\n",
        "    path=params[\"path\"]\n",
        "\n",
        "    loss_history={\"train\": [],\"val\": []} # history of loss values in each epoch\n",
        "    metric_history={\"train\": [],\"val\": []} # histroy of metric values in each epoch\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) # copy weights for best model\n",
        "    best_loss=float('inf') # initialize best loss to a large value\n",
        "\n",
        "    # main loop\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        current_lr=get_lr(opt) # get current learning rate\n",
        "        if(verbose):\n",
        "            print(f\"Epoch {epoch}/{epochs-1}, current lr={current_lr}\")\n",
        "\n",
        "        # train model on training dataset\n",
        "        model.train()\n",
        "        train_loss, train_metric=loss_epoch(model,loss_func,train_dl,check_id,opt)\n",
        "\n",
        "        # collect loss and metric for training dataset\n",
        "        loss_history[\"train\"].append(train_loss)\n",
        "        metric_history[\"train\"].append(train_metric)\n",
        "\n",
        "        # evaluate model on validation dataset\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric=loss_epoch(model,loss_func,val_dl,check_id)\n",
        "\n",
        "\n",
        "        # store best model\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # store weights into a local file\n",
        "            torch.save(model.state_dict(), path)\n",
        "            if(verbose):\n",
        "                print(\"Copied best model weights!\")\n",
        "\n",
        "        # collect loss and metric for validation dataset\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "        metric_history[\"val\"].append(val_metric)\n",
        "\n",
        "        # learning rate schedule\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        if(verbose):\n",
        "            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
        "            print('')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, loss_history, metric_history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T10:17:28.212929Z",
          "iopub.execute_input": "2022-02-23T10:17:28.213287Z",
          "iopub.status.idle": "2022-02-23T10:17:28.22525Z",
          "shell.execute_reply.started": "2022-02-23T10:17:28.213253Z",
          "shell.execute_reply": "2022-02-23T10:17:28.224157Z"
        },
        "trusted": true,
        "id": "9U3etNhrnhLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_out(loss_hist,metric_hist,epochs=None):\n",
        "\n",
        "    # Train-Validation Progress\n",
        "    fig = make_subplots(rows=1, cols=2,subplot_titles=['lost_hist','metric_hist'])\n",
        "\n",
        "    # Plot Model Learning Rate\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=loss_hist[\"train\"],\n",
        "                             name=\"train\",\n",
        "                             mode='lines',\n",
        "                             line_color='#F1C40F'),\n",
        "                  row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=loss_hist[\"val\"],\n",
        "                             name=\"val\",\n",
        "                             mode='lines',line_color='#232323'),\n",
        "                  row=1, col=1)\n",
        "    # Plot Metric\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=metric_hist[\"train\"],\n",
        "                             name=\"train\",\n",
        "                             mode='lines',\n",
        "                             line_color='#F1C40F'),\n",
        "                  row=1, col=2)\n",
        "    fig.add_trace(go.Scatter(x=[*range(1,epochs+1)],\n",
        "                             y=metric_hist[\"val\"],\n",
        "                             name=\"val\",\n",
        "                             mode='lines',line_color='#232323'),\n",
        "                  row=1, col=2)\n",
        "\n",
        "    fig.update_layout(template='plotly_white',\n",
        "                      showlegend=False,\n",
        "                      title='Learning Rate & Metric History',height=400)\n",
        "    fig.update_layout(yaxis2 = dict(range=[0.4,1]))\n",
        "    fig.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "I3aXgVoPnhLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:#F1C40F;\"><b>9.1 | RANDOM WEIGHTS RESNET MODEL</b></p>\n",
        "</div>\n",
        "\n",
        " - The first approach uses randomised weight initialisation"
      ],
      "metadata": {
        "id": "NQVTJCtcnhLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send earlier defined model to device\n",
        "device = torch.device(\"cuda:0\")\n",
        "model_resnet18.to(device)\n",
        "\n",
        "# loss function, optimiser, LR sheduler\n",
        "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "optimiser = optim.Adam(model_resnet18.parameters(), lr=1e-4)\n",
        "lr_scheduler = CosineAnnealingLR(optimiser,T_max=5,eta_min=1e-6)\n",
        "\n",
        "params_train={\n",
        " \"epochs\": 100,\n",
        " \"optimiser\": optimiser,\n",
        " \"loss_func\": loss_func,\n",
        " \"train_dl\": train_dl,\n",
        " \"val_dl\": val_dl,\n",
        " \"check_id\": False,\n",
        " \"lr_scheduler\": lr_scheduler,\n",
        " \"path\": \"resnet18.pt\",\n",
        "}\n",
        "\n",
        "# train and validate the model\n",
        "model_resnet18,loss_hist,metric_hist=train_val(model_resnet18,\n",
        "                                               params_train,\n",
        "                                               verbose=False)\n",
        "plot_out(loss_hist,metric_hist,epochs=params_train[\"epochs\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T10:29:40.670252Z",
          "iopub.execute_input": "2022-02-23T10:29:40.670599Z",
          "iopub.status.idle": "2022-02-23T10:29:58.64262Z",
          "shell.execute_reply.started": "2022-02-23T10:29:40.670569Z",
          "shell.execute_reply": "2022-02-23T10:29:58.641744Z"
        },
        "trusted": true,
        "id": "leAurKd0nhLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"color:white;display:fill;border-radius:8px;\n",
        "            background-color:#323232;font-size:150%;\n",
        "            font-family:Nexa;letter-spacing:0.5px\">\n",
        "    <p style=\"padding: 8px;color:#F1C40F;\"><b>9.2 | PRETRAINED WEIGHTS RESTNET MODEL</b></p>\n",
        "</div>\n",
        "\n",
        "- The second approach uses preloaded weights already loaded into the model"
      ],
      "metadata": {
        "id": "kF7ROxkvnhLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Send earlier defined model to device\n",
        "device = torch.device(\"cuda:0\")\n",
        "pre_resnet18.to(device)\n",
        "\n",
        "# Loss function, optimiser, LR sheduler\n",
        "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "optimiser = optim.Adam(pre_resnet18.parameters(), lr=1e-4)\n",
        "lr_scheduler = CosineAnnealingLR(optimiser,T_max=5,eta_min=1e-6)\n",
        "\n",
        "# Set Training Parameters\n",
        "params_train={\n",
        " \"epochs\": 100,\n",
        " \"optimiser\": optimiser,\n",
        " \"loss_func\": loss_func,\n",
        " \"train_dl\": train_dl,\n",
        " \"val_dl\": val_dl,\n",
        " \"check_id\": False,\n",
        " \"lr_scheduler\": lr_scheduler,\n",
        " \"path\": \"pre_resnet18.pt\",\n",
        "}\n",
        "\n",
        "# Train and validate the model\n",
        "pre_resnet18,loss_hist,metric_hist=train_val(pre_resnet18,\n",
        "                                             params_train,\n",
        "                                             verbose=False)\n",
        "\n",
        "# Plot History\n",
        "plot_out(loss_hist,metric_hist,epochs=params_train[\"epochs\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-23T10:30:53.402912Z",
          "iopub.execute_input": "2022-02-23T10:30:53.403249Z",
          "iopub.status.idle": "2022-02-23T10:30:55.581514Z",
          "shell.execute_reply.started": "2022-02-23T10:30:53.403215Z",
          "shell.execute_reply": "2022-02-23T10:30:55.580621Z"
        },
        "trusted": true,
        "id": "VB-x-LjcnhLl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}